{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "935f5ca8",
   "metadata": {},
   "source": [
    "# ASSIGNMENT-4 SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889f4e18",
   "metadata": {},
   "source": [
    "## SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9274b266",
   "metadata": {},
   "source": [
    "Sentiment analysis, also known as opinion mining, is a natural language processing (NLP) technique used to determine the sentiment or emotion expressed in a piece of text. The goal is to identify whether the expressed sentiment is positive, negative, or neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4648837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (Km²)</th>\n",
       "      <th>Density (P/Km²)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>803e9c0931</td>\n",
       "      <td>While driving u come across aggressive driving...</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>84339067</td>\n",
       "      <td>770000.0</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>1dda981140</td>\n",
       "      <td>and so another week begins. this one has got t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Madagascar</td>\n",
       "      <td>27691018</td>\n",
       "      <td>581795.0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>2c5f261ff3</td>\n",
       "      <td>Jesus heals</td>\n",
       "      <td>positive</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Uganda</td>\n",
       "      <td>45741007</td>\n",
       "      <td>199810.0</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3291</th>\n",
       "      <td>695f322a0a</td>\n",
       "      <td>I hate when you cant sleep</td>\n",
       "      <td>negative</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>4937786</td>\n",
       "      <td>68890.0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>ecfcc8230f</td>\n",
       "      <td>ahaha thats okay and thanks</td>\n",
       "      <td>positive</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>5850342</td>\n",
       "      <td>700.0</td>\n",
       "      <td>8358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3460</th>\n",
       "      <td>77a7b3282b</td>\n",
       "      <td>_mommy oh  well i hope she gets better</td>\n",
       "      <td>positive</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Estonia</td>\n",
       "      <td>1326535</td>\n",
       "      <td>42390.0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2426</th>\n",
       "      <td>63983dd792</td>\n",
       "      <td>_dubbs curse you, igloo dwellers!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>70-100</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>4105267</td>\n",
       "      <td>55960.0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>5c8a453297</td>\n",
       "      <td>My head hurts....  Can wait to see the new pho...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>night</td>\n",
       "      <td>70-100</td>\n",
       "      <td>Equatorial Guinea</td>\n",
       "      <td>1402985</td>\n",
       "      <td>28050.0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>932af12853</td>\n",
       "      <td>Hey! Let`s Follow each other! Wouldn`t that ju...</td>\n",
       "      <td>positive</td>\n",
       "      <td>night</td>\n",
       "      <td>70-100</td>\n",
       "      <td>Australia</td>\n",
       "      <td>25499884</td>\n",
       "      <td>7682300.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>52fc580b72</td>\n",
       "      <td>burning cd`s,,,,,,,,, **** outa blank disc`s</td>\n",
       "      <td>positive</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Estonia</td>\n",
       "      <td>1326535</td>\n",
       "      <td>42390.0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          textID                                               text sentiment  \\\n",
       "764   803e9c0931  While driving u come across aggressive driving...  negative   \n",
       "2291  1dda981140  and so another week begins. this one has got t...  positive   \n",
       "962   2c5f261ff3                                        Jesus heals  positive   \n",
       "3291  695f322a0a                         I hate when you cant sleep  negative   \n",
       "2346  ecfcc8230f                        ahaha thats okay and thanks  positive   \n",
       "3460  77a7b3282b             _mommy oh  well i hope she gets better  positive   \n",
       "2426  63983dd792                 _dubbs curse you, igloo dwellers!!  negative   \n",
       "1397  5c8a453297  My head hurts....  Can wait to see the new pho...   neutral   \n",
       "1808  932af12853  Hey! Let`s Follow each other! Wouldn`t that ju...  positive   \n",
       "1030  52fc580b72       burning cd`s,,,,,,,,, **** outa blank disc`s  positive   \n",
       "\n",
       "     Time of Tweet Age of User            Country  Population -2020  \\\n",
       "764          night       31-45             Turkey          84339067   \n",
       "2291         night       31-45         Madagascar          27691018   \n",
       "962          night       31-45             Uganda          45741007   \n",
       "3291       morning       46-60            Ireland           4937786   \n",
       "2346       morning       46-60          Singapore           5850342   \n",
       "3460          noon       60-70            Estonia           1326535   \n",
       "2426         night      70-100            Croatia           4105267   \n",
       "1397         night      70-100  Equatorial Guinea           1402985   \n",
       "1808         night      70-100          Australia          25499884   \n",
       "1030          noon       60-70            Estonia           1326535   \n",
       "\n",
       "      Land Area (Km²)  Density (P/Km²)  \n",
       "764          770000.0              110  \n",
       "2291         581795.0               48  \n",
       "962          199810.0              229  \n",
       "3291          68890.0               72  \n",
       "2346            700.0             8358  \n",
       "3460          42390.0               31  \n",
       "2426          55960.0               73  \n",
       "1397          28050.0               50  \n",
       "1808        7682300.0                3  \n",
       "1030          42390.0               31  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This dataset contains sentiment of users \n",
    "import pandas as pd \n",
    "df = pd.read_csv( 'sentiment.csv', encoding='latin1')\n",
    "df.sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41fe951",
   "metadata": {},
   "source": [
    "## IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9afd5559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing preprocessing module from sklearn\n",
    "from sklearn import preprocessing\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4e60e4",
   "metadata": {},
   "source": [
    "## DOWNLOADING OPINION LEXICON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84f0c66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package opinion_lexicon to\n",
      "[nltk_data]     /Users/likithareddykotla/nltk_data...\n",
      "[nltk_data]   Package opinion_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#downloads the Opinion Lexicon dataset from NLTK\n",
    "nltk.download('opinion_lexicon')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ed281c",
   "metadata": {},
   "source": [
    "## IMPORTING COMPONENTS FROM NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38377ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opinion_lexicon provides access to positive and negative words\n",
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk.tokenize import word_tokenize #word_tokenize is used for tokenization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfc0414",
   "metadata": {},
   "source": [
    "## PRINTING INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19479fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in opinion lexicon 6789\n",
      "Examples of positive words in opinion lexicon ['a+', 'abound', 'abounds', 'abundance', 'abundant', 'accessable', 'accessible', 'acclaim', 'acclaimed', 'acclamation']\n",
      "Examples of negative words in opinion lexicon ['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable', 'abominably', 'abominate', 'abomination', 'abort', 'aborted']\n"
     ]
    }
   ],
   "source": [
    "# prints total number of words in the opinion lexicon\n",
    "print('Total number of words in opinion lexicon', len(opinion_lexicon.words()))\n",
    "print('Examples of positive words in opinion lexicon',\n",
    "      opinion_lexicon.positive()[:10])     #display examples of positive and negative words from the opinion lexicon\n",
    "print('Examples of negative words in opinion lexicon',\n",
    "      opinion_lexicon.negative()[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc45d5e",
   "metadata": {},
   "source": [
    "## DOWNLOADING  'PUNTK' TOKENIZER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac6833ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/likithareddykotla/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'punkt' tokenizer is a pre-trained unsupervised machine learning model for tokenizing text into words\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240bb1ac",
   "metadata": {},
   "source": [
    "## CREATING SENTIMENT SCORING DICTIONARY FOR TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d49219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a dictionary which we can use for scoring our review text\n",
    "df.rename(columns={\"text\": \"text\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17bfc15",
   "metadata": {},
   "source": [
    "## INITIALIZING SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9632231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the positive and negative scores to be assigned to words in the word_dict dictionary.\n",
    "pos_score = 1\n",
    "neg_score = -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88df50f6",
   "metadata": {},
   "source": [
    "##  CREATING WORD DICTIONARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ed54e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the positive words to the dictionary\n",
    "word_dict = {}\n",
    "for word in opinion_lexicon.positive():\n",
    "        word_dict[word] = pos_score       #iterates through the positive words in the Opinion Lexicon and assigns each word a positive score in the dictionary\n",
    "      \n",
    "# Adding the negative words to the dictionary\n",
    "for word in opinion_lexicon.negative():\n",
    "        word_dict[word] = neg_score       #iterates throug -ve words and assigns each a -ve score in dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d774747",
   "metadata": {},
   "source": [
    "## BING_LIU_SCORE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9a31a3",
   "metadata": {},
   "source": [
    "The bing_liu_score function is a sentiment scoring function that assigns a sentiment score to a piece of text based on a predefined dictionary (word_dict). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db5da607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis function using a simple bag-of-words approach\n",
    "def bing_liu_score(text):\n",
    "    sentiment_score = 0\n",
    "    bag_of_words = word_tokenize(text.lower())  #word_tokenize splits the text into individual words.\n",
    "    for word in bag_of_words:\n",
    "        if word in word_dict:\n",
    "            sentiment_score += word_dict[word]\n",
    "    return sentiment_score  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d96238",
   "metadata": {},
   "source": [
    "## BING_LU_SCORE() FOR TEXT DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbfba24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values in the 'text' column with the string 'no review'\n",
    "df['text'].fillna('no review', inplace=True)\n",
    "df['Bing_Liu_Score'] = df['text'].apply(bing_liu_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882d28ab",
   "metadata": {},
   "source": [
    "## TOP10 ROWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0f8417fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>text</th>\n",
       "      <th>Bing_Liu_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>morning</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>noon</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>night</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>morning</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>noon</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>night</td>\n",
       "      <td>that`s great!! weee!! visitors!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>morning</td>\n",
       "      <td>I THINK EVERYONE HATES ME ON HERE   lol</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>noon</td>\n",
       "      <td>soooooo wish i could, but im in school and my...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>night</td>\n",
       "      <td>and within a short time of the last clue all ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>morning</td>\n",
       "      <td>What did you get?  My day is alright.. haven`...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Time of Tweet                                               text  \\\n",
       "0       morning  Last session of the day  http://twitpic.com/67ezh   \n",
       "1          noon   Shanghai is also really exciting (precisely -...   \n",
       "2         night  Recession hit Veronique Branquinho, she has to...   \n",
       "3       morning                                        happy bday!   \n",
       "4          noon             http://twitpic.com/4w75p - I like it!!   \n",
       "5         night                    that`s great!! weee!! visitors!   \n",
       "6       morning            I THINK EVERYONE HATES ME ON HERE   lol   \n",
       "7          noon   soooooo wish i could, but im in school and my...   \n",
       "8         night   and within a short time of the last clue all ...   \n",
       "9       morning   What did you get?  My day is alright.. haven`...   \n",
       "\n",
       "   Bing_Liu_Score  \n",
       "0               0  \n",
       "1               4  \n",
       "2              -2  \n",
       "3               1  \n",
       "4               1  \n",
       "5               1  \n",
       "6              -1  \n",
       "7               0  \n",
       "8               0  \n",
       "9               0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Previewing the sentiment analysis results for the top 10 rows\n",
    "df[['Time of Tweet',\"text\", 'Bing_Liu_Score']].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf435f3",
   "metadata": {},
   "source": [
    "## AVERAGE BING LU SENTIMENT SCORES GROUPED BY OVERALL RATINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1ddb46e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bing_Liu_Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>morning</th>\n",
       "      <td>0.174024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night</th>\n",
       "      <td>0.198642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noon</th>\n",
       "      <td>0.241935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Bing_Liu_Score\n",
       "Time of Tweet                \n",
       "morning              0.174024\n",
       "night                0.198642\n",
       "noon                 0.241935"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating the mean Bing Liu sentiment score\n",
    "df.groupby('Time of Tweet').agg({'Bing_Liu_Score':'mean'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90440fb5",
   "metadata": {},
   "source": [
    "# FLAIR ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f3d037",
   "metadata": {},
   "source": [
    "Flair supports multiple languages and provides pre-trained models for various NLP tasks, making it a versatile library for natural language processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1550e051",
   "metadata": {},
   "source": [
    "## IMPORTING ALL REQUIRED MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "116e9796",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flair for data manipulation and analysis and NLP\n",
    "import pandas as pd\n",
    "from flair.data import Sentence\n",
    "from flair.models import TextClassifier    # flairs text classifier for text classification tasks\n",
    "from flair.training_utils import EvaluationMetric\n",
    "from flair.datasets import CSVClassificationCorpus\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5628f74",
   "metadata": {},
   "source": [
    "## LOADING AND PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ad646c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('sentiment.csv', encoding='latin1')\n",
    "df.rename(columns={\"text\": \"text\"}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4d52a3",
   "metadata": {},
   "source": [
    "## HANDLING MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "006e823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values in the 'texts' column with the string 'no review'\n",
    "df['text'].fillna('no review', inplace=True)\n",
    "\n",
    "# Load Flair sentiment model\n",
    "classifier = TextClassifier.load('sentiment')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76ecab5",
   "metadata": {},
   "source": [
    "## SENTIMENT ANALYSIS USING FLAIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f04d79e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for sentiment analysis using Flair\n",
    "def flair_sentiment(text):\n",
    "    sentence = Sentence(text)\n",
    "    classifier.predict(sentence)\n",
    "    return sentence.labels[0].value\n",
    "# Apply Flair sentiment analysis to the 'texts' column\n",
    "df['Flair_Sentiment'] = df['text'].apply(flair_sentiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bac35ce",
   "metadata": {},
   "source": [
    "\n",
    "## PREVIEW FOR TOP10 ROWS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7be5f90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Time of Tweet                                               text  \\\n",
      "0       morning  Last session of the day  http://twitpic.com/67ezh   \n",
      "1          noon   Shanghai is also really exciting (precisely -...   \n",
      "2         night  Recession hit Veronique Branquinho, she has to...   \n",
      "3       morning                                        happy bday!   \n",
      "4          noon             http://twitpic.com/4w75p - I like it!!   \n",
      "5         night                    that`s great!! weee!! visitors!   \n",
      "6       morning            I THINK EVERYONE HATES ME ON HERE   lol   \n",
      "7          noon   soooooo wish i could, but im in school and my...   \n",
      "8         night   and within a short time of the last clue all ...   \n",
      "9       morning   What did you get?  My day is alright.. haven`...   \n",
      "\n",
      "  Flair_Sentiment  \n",
      "0        NEGATIVE  \n",
      "1        POSITIVE  \n",
      "2        NEGATIVE  \n",
      "3        POSITIVE  \n",
      "4        POSITIVE  \n",
      "5        POSITIVE  \n",
      "6        NEGATIVE  \n",
      "7        NEGATIVE  \n",
      "8        NEGATIVE  \n",
      "9        NEGATIVE  \n"
     ]
    }
   ],
   "source": [
    "# Previewing the sentiment analysis results for the top 10 rows\n",
    "print(df[['Time of Tweet', 'text', 'Flair_Sentiment']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab03349b",
   "metadata": {},
   "source": [
    "## COMPUTING AND DISPLAYING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54355f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flair Sentiment Distribution:\n",
      " Flair_Sentiment\n",
      "POSITIVE    1835\n",
      "NEGATIVE    1699\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculating the distribution of Flair sentiment labels\n",
    "sentiment_distribution = df['Flair_Sentiment'].value_counts()\n",
    "print(\"Flair Sentiment Distribution:\\n\", sentiment_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb0f390",
   "metadata": {},
   "source": [
    " # AFINN ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d447c9a0",
   "metadata": {},
   "source": [
    "AFINN algorithm assigns pre-defined scores (sentiment scores) to words based on their sentiment polarity. The scores range from negative to positive, with zero indicating neutrality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffb876e",
   "metadata": {},
   "source": [
    "## IMPORTING PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e8ecb529",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/likithareddykotla/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing necessary modules\n",
    "import pandas as pd\n",
    "from afinn import Afinn    #Afinn library for sentiment analysis\n",
    "from nltk.tokenize import word_tokenize    #NLTK for natural language processing, specifically word tokenization\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a843ef4f",
   "metadata": {},
   "source": [
    "## LOADING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "98429191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('sentiment.csv', encoding='latin1')\n",
    "df.rename(columns={\"text\": \"text\"}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8733a2f9",
   "metadata": {},
   "source": [
    "## REPLACING MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "00d9f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing missing values in the 'texts' column with the string 'no review'\n",
    "df['text'].fillna('no review', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d6b1f2",
   "metadata": {},
   "source": [
    "## AFFINN SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "01dfb4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Afinn\n",
    "afinn = Afinn()\n",
    "\n",
    "# Sentiment analysis function using Afinn\n",
    "def afinn_score(text):\n",
    "    return afinn.score(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b53a43",
   "metadata": {},
   "source": [
    "## ANALYSIS AND RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c1b548f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Time of Tweet                                               text  \\\n",
      "0       morning  Last session of the day  http://twitpic.com/67ezh   \n",
      "1          noon   Shanghai is also really exciting (precisely -...   \n",
      "2         night  Recession hit Veronique Branquinho, she has to...   \n",
      "3       morning                                        happy bday!   \n",
      "4          noon             http://twitpic.com/4w75p - I like it!!   \n",
      "5         night                    that`s great!! weee!! visitors!   \n",
      "6       morning            I THINK EVERYONE HATES ME ON HERE   lol   \n",
      "7          noon   soooooo wish i could, but im in school and my...   \n",
      "8         night   and within a short time of the last clue all ...   \n",
      "9       morning   What did you get?  My day is alright.. haven`...   \n",
      "\n",
      "   Afinn_Score  \n",
      "0          0.0  \n",
      "1          6.0  \n",
      "2         -4.0  \n",
      "3          3.0  \n",
      "4          2.0  \n",
      "5          3.0  \n",
      "6          0.0  \n",
      "7          0.0  \n",
      "8          0.0  \n",
      "9          0.0  \n",
      "Mean Afinn Sentiment Score:\n",
      " Time of Tweet\n",
      "morning    0.819185\n",
      "night      0.948217\n",
      "noon       1.023769\n",
      "Name: Afinn_Score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Apply Afinn sentiment analysis to the 'texts' column\n",
    "df['Afinn_Score'] = df['text'].apply(afinn_score)\n",
    "\n",
    "# Previewing the sentiment analysis results for the top 10 rows\n",
    "print(df[['Time of Tweet', 'text', 'Afinn_Score']].head(10))\n",
    "\n",
    "# Calculating the mean Afinn sentiment score\n",
    "mean_afinn_score = df.groupby('Time of Tweet')['Afinn_Score'].mean()\n",
    "print(\"Mean Afinn Sentiment Score:\\n\", mean_afinn_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57eb88c",
   "metadata": {},
   "source": [
    "# VADER ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3bf6cd",
   "metadata": {},
   "source": [
    "VADER is specifically designed for sentiment analysis and is good at handling sentiment in short texts, social media language, and emoticons.It provides compound scores of positive ,negative values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec22f17",
   "metadata": {},
   "source": [
    "## IMPORTING PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ce2e55bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/likithareddykotla/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/likithareddykotla/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing libraries and modules\n",
    "import pandas as pd\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer   #NLTK's SentimentIntensityAnalyzer for sentiment analysis\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b59744",
   "metadata": {},
   "source": [
    "## LOADING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6de30374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sentiment Data from CSV\n",
    "df = pd.read_csv('sentiment.csv', encoding='latin1')\n",
    "\n",
    "# Rename 'text' column to 'texts' for consistency\n",
    "df.rename(columns={\"text\": \"text\"}, inplace=True)    \n",
    "\n",
    "# Handle Missing Values in 'texts' Column\n",
    "df['text'].fillna('no review', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dfd046",
   "metadata": {},
   "source": [
    "## NLTKS SENTIMENTANALYSZER FOR SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3107574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Time of Tweet                                               text  \\\n",
      "0       morning  Last session of the day  http://twitpic.com/67ezh   \n",
      "1          noon   Shanghai is also really exciting (precisely -...   \n",
      "2         night  Recession hit Veronique Branquinho, she has to...   \n",
      "3       morning                                        happy bday!   \n",
      "4          noon             http://twitpic.com/4w75p - I like it!!   \n",
      "5         night                    that`s great!! weee!! visitors!   \n",
      "6       morning            I THINK EVERYONE HATES ME ON HERE   lol   \n",
      "7          noon   soooooo wish i could, but im in school and my...   \n",
      "8         night   and within a short time of the last clue all ...   \n",
      "9       morning   What did you get?  My day is alright.. haven`...   \n",
      "\n",
      "   VADER_Score  \n",
      "0       0.0000  \n",
      "1       0.7501  \n",
      "2      -0.7345  \n",
      "3       0.6114  \n",
      "4       0.4738  \n",
      "5       0.7405  \n",
      "6      -0.2103  \n",
      "7      -0.3048  \n",
      "8       0.0000  \n",
      "9       0.0000  \n",
      "Mean VADER Sentiment Score:\n",
      " Time of Tweet\n",
      "morning    0.129218\n",
      "night      0.168997\n",
      "noon       0.164653\n",
      "Name: VADER_Score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Initialize NLTK's SentimentIntensityAnalyzer for sentiment analysis\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_score(texts):\n",
    "    return sia.polarity_scores(texts)['compound']\n",
    "\n",
    "df['VADER_Score'] = df['text'].apply(vader_score)\n",
    "\n",
    "print(df[['Time of Tweet', 'text', 'VADER_Score']].head(10))\n",
    "\n",
    "mean_vader_score = df.groupby('Time of Tweet')['VADER_Score'].mean()\n",
    "print(\"Mean VADER Sentiment Score:\\n\", mean_vader_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d8d24d",
   "metadata": {},
   "source": [
    "## CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4799d66",
   "metadata": {},
   "source": [
    "For the above data set Bing_Lu_Score and Vader Algorithms are more suitable as they provide more accurate positive and negative score based on the analysis\n",
    "Bing_Lu_Score provides a numerical sentiment score it suits as to measure sentiment strength.\n",
    "Vader provides a compound sentiment score suits for obtaining a continuous sentiment score with a focus on the overall sentiment.Though we can see vader is providing us more precise sentiment scores for the dataset provided\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
